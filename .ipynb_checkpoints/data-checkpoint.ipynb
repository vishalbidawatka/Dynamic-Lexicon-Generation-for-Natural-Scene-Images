{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named gensim.parsing.preprocessing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe817e560532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSnowballStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named gensim.parsing.preprocessing"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
    "\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/home/tyagi/Downloads/Project/annotations_trainval2017/annotations/captions_val2017.json\") as file:\n",
    "#     data_val=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/tyagi/Downloads/project_data_bhavin/annotations_trainval2014/annotations/captions_val2014.json\") as file:\n",
    "    data_val=json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data_val is having all data which we load from the json file\n",
    "- data_val is dictionary with all info as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "info 6\n",
      "images 40504\n",
      "licenses 8\n",
      "annotations 202654\n"
     ]
    }
   ],
   "source": [
    "print(len(data_val))\n",
    "for i in data_val.keys():\n",
    "    print(i,len(data_val[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'COCO 2014 Dataset', 'url': 'http://cocodataset.org', 'version': '1.0', 'year': 2014, 'contributor': 'COCO Consortium', 'date_created': '2017/09/01'}\n"
     ]
    }
   ],
   "source": [
    "print(data_val[\"info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202654\n",
      "{'image_id': 537955, 'id': 41577, 'caption': 'A family pet looking up at the camera while posing for a picture.'}\n"
     ]
    }
   ],
   "source": [
    "print(len(data_val['annotations']))\n",
    "print(data_val['annotations'][1800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train is for decoration out in the front of the building. \n",
      "An old fashion train is on display on a brick stand. \n",
      "An old train engine sits on the track.\n",
      "A train parked in front of a group of buildings.\n",
      "A retired train is parked on the rock for show. \n"
     ]
    }
   ],
   "source": [
    "for images in data_val['annotations']:    \n",
    "    if images['image_id'] == 322831:\n",
    "        print(images['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer = SnowballStemmer('english')\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    \n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(lemmatize_stemming(token)) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'decoration', 'build']\n",
      "['fashion', 'train', 'display', 'brick', 'stand']\n",
      "['train', 'engine', 'track']\n",
      "['train', 'park', 'group', 'build']\n",
      "['retire', 'train', 'park', 'rock']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for images in data_val['annotations']:\n",
    "    if images['image_id'] == 322831:\n",
    "        result=preprocess(images['caption'])\n",
    "        \n",
    "        print(result)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict={}\n",
    "for image in data_val['annotations']:\n",
    "    if image[\"image_id\"] in data_dict:\n",
    "        data_dict[image[\"image_id\"]].append(image[\"caption\"])\n",
    "    else:\n",
    "        data_dict.update({image[\"image_id\"]:[image[\"caption\"]]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_dict)) ### image_id(key) -- > text_corpus(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The train is for decoration out in the front of the building. ', 'An old fashion train is on display on a brick stand. ', 'An old train engine sits on the track.', 'A train parked in front of a group of buildings.', 'A retired train is parked on the rock for show. ']\n"
     ]
    }
   ],
   "source": [
    "print(data_dict[322831])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data_dict.items(),columns=['image_id','text_corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A bicycle replica with a clock as the front wheel.',\n",
       " 'The bike has a clock as a tire.',\n",
       " 'A black metal bicycle with a clock inside the front wheel.',\n",
       " 'A bicycle figurine in which the front wheel is replaced with a clock\\n',\n",
       " 'A clock with the appearance of the wheel of a bicycle ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['text_corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203564</td>\n",
       "      <td>[A bicycle replica with a clock as the front w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179765</td>\n",
       "      <td>[A black Honda motorcycle parked in front of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322141</td>\n",
       "      <td>[A room with blue walls and a white sink and d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16977</td>\n",
       "      <td>[A car that seems to be parked illegally behin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106140</td>\n",
       "      <td>[A large passenger airplane flying through the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                        text_corpus\n",
       "0    203564  [A bicycle replica with a clock as the front w...\n",
       "1    179765  [A black Honda motorcycle parked in front of a...\n",
       "2    322141  [A room with blue walls and a white sink and d...\n",
       "3     16977  [A car that seems to be parked illegally behin...\n",
       "4    106140  [A large passenger airplane flying through the..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40504, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemm(text):\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocessing(Bigtext):\n",
    "    \n",
    "    result = []\n",
    "    for text in Bigtext:\n",
    "        for token in gensim.utils.simple_preprocess(text):\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(lemmatize_stemm(token)) > 3:\n",
    "                #print(token)\n",
    "                result.append(lemmatize_stemm(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gensim={}\n",
    "for i in range(df.shape[0]):\n",
    "    dict_gensim.update({i:preprocessing(df.iloc[i][\"text_corpus\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bicycle', 'replica', 'clock', 'wheel', 'bike', 'clock', 'tire', 'black', 'metal', 'bicycle', 'clock', 'inside', 'wheel', 'bicycle', 'figurine', 'wheel', 'replace', 'clock', 'clock', 'appearance', 'wheel', 'bicycle']\n"
     ]
    }
   ],
   "source": [
    "print(dict_gensim[0])\n",
    "dd=pd.Series(dict_gensim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "(40504,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [bicycle, replica, clock, wheel, bike, clock, ...\n",
       "1    [black, honda, motorcycle, park, garage, honda...\n",
       "2    [room, blue, wall, white, sink, door, blue, wh...\n",
       "3    [park, illegally, legally, park, cars, park, s...\n",
       "4    [large, passenger, airplane, plane, take, part...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(dd))\n",
    "print(dd.shape)\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(dd)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12482 unique tokens: ['appearance', 'bicycle', 'bike', 'black', 'clock']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 appearance\n",
      "1 bicycle\n",
      "2 bike\n",
      "3 black\n",
      "4 clock\n",
      "5 figurine\n",
      "6 inside\n",
      "7 metal\n",
      "8 replace\n",
      "9 replica\n",
      "10 tire\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12482"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in dd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 3 (\"black\") appears 2 time.\n",
      "Word 12 (\"brake\") appears 1 time.\n",
      "Word 13 (\"burgundy\") appears 1 time.\n",
      "Word 14 (\"dark\") appears 1 time.\n",
      "Word 15 (\"driveway\") appears 1 time.\n",
      "Word 16 (\"extend\") appears 1 time.\n",
      "Word 17 (\"garage\") appears 2 time.\n",
      "Word 18 (\"grass\") appears 1 time.\n",
      "Word 19 (\"gravel\") appears 1 time.\n",
      "Word 20 (\"honda\") appears 3 time.\n",
      "Word 21 (\"motorcycle\") appears 5 time.\n",
      "Word 22 (\"outside\") appears 1 time.\n",
      "Word 23 (\"park\") appears 3 time.\n",
      "Word 24 (\"seat\") appears 1 time.\n",
      "Word 25 (\"stand\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_1 = bow_corpus[1]\n",
    "\n",
    "for i in range(len(bow_doc_1)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_1[i][0],dictionary[bow_doc_1[i][0]], bow_doc_1[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.120*\"clock\" + 0.070*\"horse\" + 0.069*\"build\" + 0.049*\"tower\" + 0.044*\"frisbee\" + 0.036*\"large\" + 0.035*\"truck\" + 0.022*\"soccer\" + 0.018*\"tall\" + 0.018*\"white\"\n",
      "Topic: 1 \n",
      "Words: 0.097*\"sign\" + 0.044*\"umbrella\" + 0.040*\"motorcycle\" + 0.030*\"scissor\" + 0.029*\"stop\" + 0.024*\"street\" + 0.021*\"pair\" + 0.018*\"airplane\" + 0.017*\"blue\" + 0.017*\"plane\"\n",
      "Topic: 2 \n",
      "Words: 0.107*\"people\" + 0.057*\"baseball\" + 0.051*\"group\" + 0.043*\"play\" + 0.042*\"bear\" + 0.037*\"game\" + 0.035*\"stand\" + 0.032*\"snow\" + 0.023*\"teddy\" + 0.020*\"player\"\n",
      "Topic: 3 \n",
      "Words: 0.079*\"street\" + 0.061*\"phone\" + 0.050*\"park\" + 0.038*\"cell\" + 0.033*\"city\" + 0.031*\"bench\" + 0.026*\"walk\" + 0.024*\"light\" + 0.024*\"road\" + 0.021*\"build\"\n",
      "Topic: 4 \n",
      "Words: 0.115*\"train\" + 0.090*\"skateboard\" + 0.045*\"track\" + 0.034*\"board\" + 0.032*\"trick\" + 0.030*\"jump\" + 0.029*\"skate\" + 0.026*\"station\" + 0.025*\"person\" + 0.017*\"ramp\"\n",
      "Topic: 5 \n",
      "Words: 0.055*\"stand\" + 0.043*\"water\" + 0.037*\"beach\" + 0.032*\"field\" + 0.028*\"kite\" + 0.028*\"grass\" + 0.026*\"surfboard\" + 0.024*\"tree\" + 0.023*\"wave\" + 0.021*\"walk\"\n",
      "Topic: 6 \n",
      "Words: 0.154*\"tennis\" + 0.051*\"court\" + 0.050*\"ball\" + 0.041*\"bathroom\" + 0.038*\"racket\" + 0.034*\"player\" + 0.030*\"toilet\" + 0.025*\"hold\" + 0.025*\"play\" + 0.024*\"sink\"\n",
      "Topic: 7 \n",
      "Words: 0.075*\"table\" + 0.049*\"plate\" + 0.039*\"pizza\" + 0.038*\"food\" + 0.029*\"laptop\" + 0.023*\"desk\" + 0.022*\"cake\" + 0.016*\"sandwich\" + 0.015*\"white\" + 0.015*\"glass\"\n",
      "Topic: 8 \n",
      "Words: 0.101*\"woman\" + 0.063*\"hold\" + 0.036*\"stand\" + 0.030*\"kitchen\" + 0.030*\"girl\" + 0.026*\"young\" + 0.023*\"wear\" + 0.023*\"person\" + 0.019*\"boat\" + 0.018*\"look\"\n",
      "Topic: 9 \n",
      "Words: 0.058*\"room\" + 0.030*\"table\" + 0.029*\"live\" + 0.028*\"flower\" + 0.024*\"vase\" + 0.024*\"chair\" + 0.020*\"white\" + 0.020*\"window\" + 0.016*\"wall\" + 0.015*\"couch\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It describe the Prob each document which is distribution of different topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.3007987), (6, 0.4188576), (7, 0.2558371)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model[bow_corpus[500]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing the ${Prob(topic/text)}$  which works as  y for our inception model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict={}\n",
    "for j in range(len(bow_corpus)):\n",
    "    li=[0.0]*num_topics  ### len == no of topics\n",
    "    probDist=lda_model[bow_corpus[j]]\n",
    "    for i in range(len(probDist)):\n",
    "        li[probDist[i][0]]=probDist[i][1]\n",
    "    final_dict[df.iloc[j][\"image_id\"]]=li\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40504"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "f=open(\"ldaResult\",\"wb\") \n",
    "pickle.dump(final_dict,f)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing the ${Prob(word/topic)}$  which works as  y  for our inception model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_prob={}\n",
    "for i in range(num_topics):\n",
    "    word_prob={}\n",
    "    ss=lda_model.get_topic_terms(i,topn=75)\n",
    "    for x in ss:\n",
    "        word_prob[dictionary[x[0]]]=x[1]\n",
    "    topic_word_prob[i]=word_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"topic_word_prob\",\"wb\") as f:\n",
    "    pickle.dump(topic_word_prob,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
